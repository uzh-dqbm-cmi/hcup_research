{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define relevant directories\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "# project directory\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# src directory \n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "sys.path.insert(0, src_dir)\n",
    "print(\"src_dir \", src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROCESSORS = mp.cpu_count() - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # specify the visibile devices (if preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(dataset_dir, dsettypes, wrk_dir, model_class,\n",
    "                         num_epochs, to_gpu, memmap, options={}): \n",
    "    # get parameter configurations\n",
    "    prob_interval_truemax=0.03\n",
    "    prob_estim = 0.95\n",
    "    rnn_class = True\n",
    "    crf_mode = None\n",
    "    target_fold = \"subsetfold_none\"\n",
    "    if(model_class == 'RNN_Labeler'):\n",
    "        alpha_param = True\n",
    "        sampling_func = False\n",
    "        y_codebook = {0:0, 1:1}\n",
    "        model_train = rnn_run\n",
    "    elif(model_class ==  'RNNSS_Labeler'):\n",
    "        alpha_param = True\n",
    "        sampling_func = True\n",
    "        y_codebook = {0:0, 1:1, '__START__':2}\n",
    "        model_train = rnnss_run\n",
    "    elif(model_class in {'CRF_Labeler', 'CRF_Pair_Labeler', \n",
    "                         'RNNCRF_Pair_Labeler', 'RNNCRF_Unary_Labeler'}):\n",
    "        alpha_param = False\n",
    "        sampling_func = False\n",
    "        y_codebook = {0:0, 1:1, '__START__':2}\n",
    "        model_train = rnncrf_run\n",
    "        if(model_class == 'CRF_Labeler'):\n",
    "            crf_type = options.get('crf_type') # {nn_crf, only_crf}\n",
    "            rnn_class = False\n",
    "            if(crf_type == 'nn_crf'):\n",
    "                crf_mode = 'crf'\n",
    "            else:\n",
    "                crf_mode = 'crf_nn'\n",
    "        stopstate_symb = options.get('stopstate_symb')\n",
    "        if(stopstate_symb):\n",
    "            y_codebook[stopstate_symb] = len(y_codebook)\n",
    "    elif(model_class in {'CNN_Labeler', 'CNNWide_Labeler', 'NN_Labeler'}):\n",
    "        y_codebook = {0:0,1:1}\n",
    "        model_train = cnn_nn_run\n",
    "        options['cnn_type'] = model_class\n",
    "        \n",
    "    classweight_option = options.get('classweight_option')\n",
    "    target_dsets, input_shape = load_dataset(os.path.join(dataset_dir, target_fold, 'dataset_tuple.pkl'),\n",
    "                                             dsettypes, \n",
    "                                             memmap)\n",
    "    if(classweight_option):\n",
    "        class_weights = ReaderWriter.read_data(os.path.join(dataset_dir,\n",
    "                                                            target_fold,\n",
    "                                                            'train_pdtm', \n",
    "                                                            'classweights_'+classweight_option+'.pkl'))\n",
    "        options['class_weights'] = class_weights    \n",
    "\n",
    "    if(model_class in {'CNN_Labeler', 'CNNWide_Labeler'}):\n",
    "        # C: channels, H: y-dimension of the matrix, W: x-dimension of the matrix\n",
    "        C, H, W = 1, input_shape[-2], input_shape[-1]\n",
    "        configs= get_config_cnn((C, H, W), model_class, prob_interval_truemax, prob_estim)\n",
    "    elif(model_class == 'NN_Labeler'):\n",
    "        input_dim = input_shape[-1] # number of input features\n",
    "        configs = get_config_nn(input_dim, prob_interval_truemax, prob_estim)\n",
    "    else:\n",
    "        input_dim = input_shape[-1] # number of input features\n",
    "        configs = get_config(input_dim, prob_interval_truemax, prob_estim, \n",
    "                             alpha_param=alpha_param, sampling_func=sampling_func,\n",
    "                             rnn_class=rnn_class, crf_mode=crf_mode)\n",
    "    args = []\n",
    "    model_dirs = []\n",
    "    for i, config in enumerate(configs):\n",
    "        # create a new version for each configuration\n",
    "        target_dsets, __ = load_dataset(os.path.join(dataset_dir, target_fold, 'dataset_tuple.pkl'),\n",
    "                                        dsettypes, \n",
    "                                        memmap)\n",
    "        # setup target dir\n",
    "        target_dir = create_directory('out_{}'.format(i), wrk_dir)\n",
    "        model_dirs.append(target_dir)\n",
    "        args.append((config, model_class, target_dsets, y_codebook, num_epochs,\n",
    "                     target_dir, i, to_gpu, memmap, None, options))\n",
    "    # pickle the configs\n",
    "    ReaderWriter.dump_data(configs, os.path.join(wrk_dir, 'configs.pkl'))\n",
    "    num_processors = mp.cpu_count()-1\n",
    "    num_models = len(args)\n",
    "    outlog = os.path.join(wrk_dir, 'out.log')\n",
    "\n",
    "    if(num_processors > NUM_PROCESSORS):\n",
    "        num_processors = NUM_PROCESSORS\n",
    "    if(num_models < num_processors):\n",
    "        num_processors = num_models\n",
    "    print(\"number of models to be evaluted: \", num_models)\n",
    "    print(\"number of processors to be used: \", num_processors)\n",
    "    \n",
    "    processes = []\n",
    "    counter = 0\n",
    "    tick = datetime.datetime.now()\n",
    "    while len(args):\n",
    "        if(len(args) < num_processors):\n",
    "            num_processors = len(args)\n",
    "        for __ in range(num_processors):\n",
    "            arg = args.pop()\n",
    "            p = mp.Process(target=model_train, args=arg)\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "            print(\"counter \", counter)\n",
    "            counter+=1\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "            print(\"we are joining {}\".format(p))\n",
    "    tock = datetime.datetime.now()\n",
    "    line = \"total number of seconds: {}\\n\".format((tock-tick).seconds)\n",
    "    ReaderWriter.write_log(line, outlog, mode='a')\n",
    "    scores = get_perfscores(model_dirs, 'validation', outlog, wrk_dir)\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_optimzmodel_dir =  create_directory('hyperparam_optimz_models', project_dir)\n",
    "dataset_dir = os.path.join(project_dir, 'dataset_neural')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN/RNNSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking __main__ condition helps preventing \"weird\" issues when running multiprocesses on Windows OS!!\n",
    "if __name__ == \"__main__\":\n",
    "    to_gpu = True # run on GPU\n",
    "    memmap = True # data is memory mapped originally using numpy memmap\n",
    "    bidirection = False\n",
    "    classweight_option = 'last_indx'\n",
    "    loss_mode = 'Convex_HF_LastHF'\n",
    "    rgrad_mode = 'clip_norm'\n",
    "    rgrad_limit = (None, 1) \n",
    "    model_classes = ('RNN_Labeler', 'RNNSS_Labeler')\n",
    "    prefixes = ('rnn', 'rnnss')    \n",
    "    # hyperparam optimization phase\n",
    "    num_epochs = 25\n",
    "    for i, model_class in enumerate(model_classes):\n",
    "        print(\"model class: \", model_class)\n",
    "        prefix = prefixes[i]\n",
    "        wrk_dir = create_directory(prefix, hyperparam_optimzmodel_dir)\n",
    "        scoredict = optimize_hyperparams(dataset_dir, ['train', 'validation'], \n",
    "                                         wrk_dir, model_class,\n",
    "                                         num_epochs, to_gpu, memmap,\n",
    "                                         {'classweight_option':classweight_option,\n",
    "                                          'reg_type':'l2',\n",
    "                                          'loss_mode':loss_mode,\n",
    "                                          'bidirection':bidirection,\n",
    "                                          'rgrad_mode':rgrad_mode,\n",
    "                                          'rgrad_limit':rgrad_limit})\n",
    "        print(scoredict)\n",
    "        print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN/CNNWide/MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    to_gpu = True\n",
    "    memmap = True\n",
    "    classweight_option = 'last_indx'    \n",
    "    rgrad_mode = 'clip_norm'\n",
    "    rgrad_limit = (None, 1)\n",
    "    model_classes = ('CNN_Labeler', 'CNNWide_Labeler', 'NN_Labeler')\n",
    "    prefixes = ('cnn', 'cnnwide', 'nn')\n",
    "    num_epochs = 25\n",
    "    for i, model_class in enumerate(model_classes):\n",
    "        prefix = prefixes[i]\n",
    "        wrk_dir = create_directory(prefix, hyperparam_optimzmodel_dir)\n",
    "        scoredict = optimize_hyperparams(dataset_dir, ['train', 'validation'], \n",
    "                                         wrk_dir, model_class,\n",
    "                                         num_epochs, to_gpu, memmap,\n",
    "                                         {'classweight_option':classweight_option,\n",
    "                                          'reg_type':'l2',\n",
    "                                          'rgrad_mode':rgrad_mode,\n",
    "                                          'rgrad_limit':rgrad_limit})\n",
    "        print(scoredict)\n",
    "        print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNCRF {Pair, Unary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    to_gpu = True\n",
    "    memmap = True\n",
    "    bidirection = False\n",
    "    decoder_type = 'viterbi'\n",
    "    rgrad_mode = 'clip_norm'\n",
    "    rgrad_limit = (None, 1)\n",
    "    model_classes = ('RNNCRF_Pair_Labeler', 'RNNCRF_Unary_Labeler')\n",
    "    prefixes = ('rnncrfpair', 'rnncrfunary')\n",
    "    num_epochs = 25\n",
    "    for i, model_class in enumerate(model_classes):\n",
    "        prefix = prefixes[i]\n",
    "        wrk_dir = create_directory(prefix, hyperparam_optimzmodel_dir)\n",
    "        scoredict = optimize_hyperparams(dataset_dir, ['train', 'validation'], \n",
    "                                         wrk_dir, model_class,\n",
    "                                         num_epochs, to_gpu, memmap,\n",
    "                                         {'reg_type':'l2',\n",
    "                                          'decoder_type':decoder_type,\n",
    "                                          'bidirection':bidirection,\n",
    "                                          'rgrad_mode':rgrad_mode,\n",
    "                                          'rgrad_limit':rgrad_limit})\n",
    "        print(scoredict)\n",
    "        print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRF/Neural CRF {Pair, Unary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    to_gpu = True\n",
    "    memmap = True\n",
    "    decoder_type = 'viterbi'\n",
    "    rgrad_mode = 'clip_norm'\n",
    "    rgrad_limit = (None, 1)\n",
    "    model_classes = ('CRF_Pair_Labeler', 'CRF_Labeler')\n",
    "    crf_types = ('nn','only')\n",
    "    num_epochs = 25\n",
    "    for model_class in model_classes:\n",
    "        for crf_type in crf_types:\n",
    "            if('Pair' in model_class):\n",
    "                prefix = 'crf{}pair'.format(crf_type)\n",
    "            else:\n",
    "                prefix = 'crf{}'.format(crf_type)\n",
    "            wrk_dir = create_directory(prefix, hyperparam_optimzmodel_dir)\n",
    "            scoredict = optimize_hyperparams(dataset_dir, ['train', 'validation'], \n",
    "                                             wrk_dir, model_class,\n",
    "                                             num_epochs, to_gpu, memmap,\n",
    "                                             {'reg_type':'l2',\n",
    "                                              'decoder_type':decoder_type,\n",
    "                                              'crf_type': '{}_crf'.format(crf_type),\n",
    "                                              'bidirection':bidirection,\n",
    "                                              'rgrad_mode':rgrad_mode,\n",
    "                                              'rgrad_limit':rgrad_limit})\n",
    "            print(scoredict)\n",
    "            print(\"-\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
